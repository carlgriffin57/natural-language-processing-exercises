{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "\n",
    "import acquire\n",
    "import prepare\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the inshorts article data, practice using the modeling tools for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acquire**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Customers of banks under moratorium to get ₹5 ...</td>\n",
       "      <td>Finance Minister Nirmala Sitharaman today anno...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>₹3 lakh fine on Shilpa, Raj &amp; his firm by SEBI...</td>\n",
       "      <td>Securities and Exchange Board of India (SEBI) ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Old video of people laughing as Bezos talks ab...</td>\n",
       "      <td>An old video of Amazon Founder Jeff Bezos has ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple, Alphabet, Microsoft post combined quart...</td>\n",
       "      <td>Three of the world's largest tech companies - ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This information isn't collected by govt: FM o...</td>\n",
       "      <td>Finance Minister Nirmala Sitharaman replied \"t...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Customers of banks under moratorium to get ₹5 ...   \n",
       "1  ₹3 lakh fine on Shilpa, Raj & his firm by SEBI...   \n",
       "2  Old video of people laughing as Bezos talks ab...   \n",
       "3  Apple, Alphabet, Microsoft post combined quart...   \n",
       "4  This information isn't collected by govt: FM o...   \n",
       "\n",
       "                                             content  category  \n",
       "0  Finance Minister Nirmala Sitharaman today anno...  business  \n",
       "1  Securities and Exchange Board of India (SEBI) ...  business  \n",
       "2  An old video of Amazon Founder Jeff Bezos has ...  business  \n",
       "3  Three of the world's largest tech companies - ...  business  \n",
       "4  Finance Minister Nirmala Sitharaman replied \"t...  business  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Acquire the data using the function from the acquire module\n",
    "categories = [\"business\", \"sports\", \"technology\", \"entertainment\", \"science\", \"world\"]\n",
    "news_df = acquire.get_all_news_articles(categories)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "news_df['clean'] = news_df['content'].apply(lambda x: prepare.remove_stopwords(prepare.tokenize(prepare.basic_clean(x))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>finance minister nirmala sitharaman today anno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>securities exchange board india sebi imposed 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>old video amazon founder jeff bezos gone viral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>three world ' largest tech companies apple goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>finance minister nirmala sitharaman replied in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                              clean\n",
       "0  business  finance minister nirmala sitharaman today anno...\n",
       "1  business  securities exchange board india sebi imposed 3...\n",
       "2  business  old video amazon founder jeff bezos gone viral...\n",
       "3  business  three world ' largest tech companies apple goo...\n",
       "4  business  finance minister nirmala sitharaman replied in..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Subset the data into a df with just the clean and category columns\n",
    "df = news_df[['category', 'clean']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use this split function later to create in-sample and out-of-sample datasets for modeling\n",
    "def split(df, stratify_by=None):\n",
    "    \"\"\"\n",
    "    3 way split for train, validate, and test datasets\n",
    "    To stratify, send in a column name\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df[stratify_by])\n",
    "    \n",
    "    train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train[stratify_by])\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the data and stratify by category\n",
    "train, validate, test = split(df, 'category')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our X variables\n",
    "X_train = train.clean\n",
    "X_validate = validate.clean\n",
    "X_test = test.clean\n",
    "\n",
    "# Setup our y variables\n",
    "y_train = train.category\n",
    "y_validate = validate.category\n",
    "y_test = test.category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "science          25\n",
       "sports           25\n",
       "technology       24\n",
       "world            24\n",
       "business         24\n",
       "entertainment    24\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Establish baseline\n",
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the tfidf vectorizer object\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "#Fit the object on the training data\n",
    "tfidf.fit(X_train)\n",
    "\n",
    "#Use the object\n",
    "X_train_vectorized =tfidf.transform(X_train)\n",
    "X_validate_vectorized =tfidf.transform(X_validate) \n",
    "X_test_vectorized =tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the vectorized data, make a logistic regression model\n",
    "lm = LogisticRegression()\n",
    "\n",
    "#Fit the lm object to the vectorized data\n",
    "lm.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create corresponding dataframes for the actual values of the categories that correspond to each article\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Form predictions uisng the lm model\n",
    "train['predicted'] = lm.predict(X_train_vectorized)\n",
    "validate[\"predicted\"] = lm.predict(X_validate_vectorized)\n",
    "test['predicted'] = lm.predict(X_test_vectorized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.92      0.92      0.92        13\n",
      "entertainment       1.00      1.00      1.00        13\n",
      "      science       1.00      1.00      1.00        14\n",
      "       sports       1.00      1.00      1.00        14\n",
      "   technology       0.92      0.92      0.92        13\n",
      "        world       1.00      1.00      1.00        14\n",
      "\n",
      "     accuracy                           0.98        81\n",
      "    macro avg       0.97      0.97      0.97        81\n",
      " weighted avg       0.98      0.98      0.98        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Review how the lm model performed on the in-sample data\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.83      0.83      0.83         6\n",
      "entertainment       0.80      0.67      0.73         6\n",
      "      science       0.80      0.67      0.73         6\n",
      "       sports       0.80      0.67      0.73         6\n",
      "   technology       0.33      0.17      0.22         6\n",
      "        world       0.45      1.00      0.62         5\n",
      "\n",
      "     accuracy                           0.66        35\n",
      "    macro avg       0.67      0.67      0.64        35\n",
      " weighted avg       0.68      0.66      0.64        35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Review how the lm model performed on the out-of-sample data\n",
    "print(classification_report(validate.actual, validate.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "- The Linear Regression model performed better on the train for all articles than the validate.\n",
    "- Technology and world performed the worst on the validate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the KNN object with a k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "\n",
    "#Fit the object to the vectorized training data\n",
    "knn.fit(X_train_vectorized, y_train)\n",
    "\n",
    "#Create corresponding dataframes for the actual values of the categories that correspond to each article\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "#Form predictions uisng the knn model\n",
    "train['predicted'] = knn.predict(X_train_vectorized)\n",
    "validate[\"predicted\"] = knn.predict(X_validate_vectorized)\n",
    "test['predicted'] = knn.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.67      0.92      0.77        13\n",
      "entertainment       0.82      0.69      0.75        13\n",
      "      science       0.72      0.93      0.81        14\n",
      "       sports       0.87      0.93      0.90        14\n",
      "   technology       0.67      0.46      0.55        13\n",
      "        world       0.90      0.64      0.75        14\n",
      "\n",
      "     accuracy                           0.77        81\n",
      "    macro avg       0.77      0.76      0.75        81\n",
      " weighted avg       0.78      0.77      0.76        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Review how the knn model performed on the in-sample data\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.60      1.00      0.75         6\n",
      "entertainment       0.67      0.67      0.67         6\n",
      "      science       0.67      0.67      0.67         6\n",
      "       sports       0.67      0.67      0.67         6\n",
      "   technology       0.00      0.00      0.00         6\n",
      "        world       0.67      0.80      0.73         5\n",
      "\n",
      "     accuracy                           0.63        35\n",
      "    macro avg       0.54      0.63      0.58        35\n",
      " weighted avg       0.54      0.63      0.58        35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Review how the knn model performed on the out-of-sample data\n",
    "print(classification_report(validate.actual, validate.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "\n",
    "- The KNN model was best able to predict the category for entertainment, science, sports and world articles\n",
    "- Technology predictions were the worst\n",
    "- Overall, the KNN model performed worst that the logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does the KNN model do with a higher k? k = 10?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the KNN object with a k = 10\n",
    "knn = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "\n",
    "#Fit the object to the vectorized training data\n",
    "knn.fit(X_train_vectorized, y_train)\n",
    "\n",
    "#Create corresponding dataframes for the actual values of the categories that correspond to each article\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "#Form predictions uisng the knn model\n",
    "train['predicted'] = knn.predict(X_train_vectorized)\n",
    "validate[\"predicted\"] = knn.predict(X_validate_vectorized)\n",
    "test['predicted'] = knn.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.63      0.92      0.75        13\n",
      "entertainment       0.83      0.77      0.80        13\n",
      "      science       0.88      1.00      0.93        14\n",
      "       sports       0.86      0.86      0.86        14\n",
      "   technology       0.75      0.46      0.57        13\n",
      "        world       0.83      0.71      0.77        14\n",
      "\n",
      "     accuracy                           0.79        81\n",
      "    macro avg       0.80      0.79      0.78        81\n",
      " weighted avg       0.80      0.79      0.78        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Review how the knn model performed on the in-sample data\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.71      0.83      0.77         6\n",
      "entertainment       0.57      0.67      0.62         6\n",
      "      science       0.67      0.67      0.67         6\n",
      "       sports       0.67      0.67      0.67         6\n",
      "   technology       0.00      0.00      0.00         6\n",
      "        world       0.67      0.80      0.73         5\n",
      "\n",
      "     accuracy                           0.60        35\n",
      "    macro avg       0.55      0.61      0.57        35\n",
      " weighted avg       0.54      0.60      0.57        35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Review how the knn model performed on the out-of-sample data\n",
    "print(classification_report(validate.actual, validate.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaway:**\n",
    "\n",
    "- Overall, the KNN model with k = 10 performed better than k=5, but still worse than the logistic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Model**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the RF object\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=15, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.89\n"
     ]
    }
   ],
   "source": [
    "#Fit the RF object to the training data\n",
    "rf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "#Predict on y\n",
    "y_pred = rf.predict(X_train_vectorized)\n",
    "\n",
    "#Evaluate\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train_vectorized, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.91      0.77      0.83        13\n",
      "entertainment       1.00      0.85      0.92        13\n",
      "      science       0.93      0.93      0.93        14\n",
      "       sports       1.00      0.93      0.96        14\n",
      "   technology       0.79      0.85      0.81        13\n",
      "        world       0.78      1.00      0.88        14\n",
      "\n",
      "     accuracy                           0.89        81\n",
      "    macro avg       0.90      0.89      0.89        81\n",
      " weighted avg       0.90      0.89      0.89        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict using in-sample data\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.60      0.50      0.55         6\n",
      "entertainment       1.00      0.67      0.80         6\n",
      "      science       0.40      0.33      0.36         6\n",
      "       sports       0.83      0.83      0.83         6\n",
      "   technology       0.25      0.17      0.20         6\n",
      "        world       0.36      0.80      0.50         5\n",
      "\n",
      "     accuracy                           0.54        35\n",
      "    macro avg       0.57      0.55      0.54        35\n",
      " weighted avg       0.58      0.54      0.54        35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict using out of sample data\n",
    "y_pred = rf.predict(X_validate_vectorized)\n",
    "\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaway:**\n",
    "\n",
    "RF does not do well, even when changing max_depth and min_sample_leaves\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validate Model Performance Using the Best Performing Model on the Validate DF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the tfidf vectorizer object\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "#Fit the object on the training data\n",
    "tfidf.fit(X_train)\n",
    "\n",
    "#Use the object\n",
    "X_train_vectorized =tfidf.transform(X_train)\n",
    "X_validate_vectorized =tfidf.transform(X_validate) \n",
    "X_test_vectorized =tfidf.transform(X_test)\n",
    "\n",
    "#Using the vectorized data, make a logistic regression model\n",
    "lm = LogisticRegression()\n",
    "\n",
    "#Fit the lm object to the vectorized data\n",
    "lm.fit(X_train_vectorized, y_train)\n",
    "\n",
    "#Create corresponding dataframes for the actual values of the categories that correspond to each article\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "#Form predictions uisng the lm model\n",
    "train['predicted'] = lm.predict(X_train_vectorized)\n",
    "validate[\"predicted\"] = lm.predict(X_validate_vectorized)\n",
    "test['predicted'] = lm.predict(X_test_vectorized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.50      0.40      0.44         5\n",
      "entertainment       1.00      0.80      0.89         5\n",
      "      science       0.57      0.80      0.67         5\n",
      "       sports       1.00      0.80      0.89         5\n",
      "   technology       0.50      0.20      0.29         5\n",
      "        world       0.44      0.80      0.57         5\n",
      "\n",
      "     accuracy                           0.63        30\n",
      "    macro avg       0.67      0.63      0.62        30\n",
      " weighted avg       0.67      0.63      0.62        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Review how the knn model performed on the out-of-sample data\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "\n",
    "- The LM model accurately predicts entertainment and sports articles 100% of the time.\n",
    "- It does not perform as well as the model did on the validate data for the other categories and it has a accuracy of  44% for classifying world articles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
